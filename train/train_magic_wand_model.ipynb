{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BtkMGSYQOTQ"
      },
      "source": [
        "# Train a gesture recognition model for microcontroller (ESP32) use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaFfr7DHRmGF"
      },
      "source": [
        "This notebook demonstrates how to train a 20kb gesture recognition model for [TensorFlow Lite for Microcontrollers](https://tensorflow.org/lite/microcontrollers/overview). It will produce the same model used in the [magic_wand_esp32_mpu6050](https://github.com/stefan/MagicWand-TFLite-ESP32-MPU6050/blob/main/magic_wand_esp32_mpu6050) application.\n",
        "\n",
        "The model is designed to be used with [Google Colaboratory](https://colab.research.google.com).\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/stefan-spiss/MagicWand-TFLite-ESP32-MPU6050/blob/main/train/train_magic_wand_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/stefan-spiss/MagicWand-TFLite-ESP32-MPU6050/blob/main/train/train_magic_wand_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXgS6rxyT7Qk"
      },
      "source": [
        "Training is much faster using GPU acceleration. Before you proceed, ensure you are using a GPU runtime by going to **Runtime -> Change runtime type** and selecting **GPU**. Training will take around 5 minutes on a GPU runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG6ErX5FRIaV"
      },
      "source": [
        "## Configure dependencies\n",
        "\n",
        "Run the following cell to ensure the correct version of TensorFlow is used."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q5VQIRp5ZUva"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STNft9TrfoVh"
      },
      "source": [
        "We'll also clone the TensorFlow repository, which contains the training scripts, and copy them into our workspace."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################ Info: check where we start.\n",
        "!pwd\n",
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7T-EQl3gZKdN",
        "outputId": "e3ea60cb-1788-4cc0-d31d-5966ad498fa4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp\n",
            "total 76\n",
            "srwxr-xr-x 1 root root     0 Dec  5 05:44 colab_runtime.sock\n",
            "-rw-r--r-- 1 root root  1299 Dec  5 05:44 dap_multiplexer.628a85fb2680.root.log.INFO.20241205-054419.114\n",
            "lrwxrwxrwx 1 root root    62 Dec  5 05:44 dap_multiplexer.INFO -> dap_multiplexer.628a85fb2680.root.log.INFO.20241205-054419.114\n",
            "srwxr-xr-x 1 root root     0 Dec  5 05:44 debugger_2az7cn5c5v\n",
            "drwx------ 2 root root  4096 Dec  5 05:48 initgoogle_syslog_dir.0\n",
            "-rw-r--r-- 1 root root  7238 Dec  5 05:53 language_service.628a85fb2680.root.log.ERROR.20241205-055318.1087\n",
            "-rw-r--r-- 1 root root 12819 Dec  5 05:54 language_service.628a85fb2680.root.log.INFO.20241205-054805.1087\n",
            "-rw-r--r-- 1 root root  2924 Dec  5 05:58 language_service.628a85fb2680.root.log.INFO.20241205-055445.2833\n",
            "-rw-r--r-- 1 root root  7238 Dec  5 05:53 language_service.628a85fb2680.root.log.WARNING.20241205-055318.1087\n",
            "lrwxrwxrwx 1 root root    65 Dec  5 05:53 language_service.ERROR -> language_service.628a85fb2680.root.log.ERROR.20241205-055318.1087\n",
            "lrwxrwxrwx 1 root root    64 Dec  5 05:54 language_service.INFO -> language_service.628a85fb2680.root.log.INFO.20241205-055445.2833\n",
            "lrwxrwxrwx 1 root root    67 Dec  5 05:53 language_service.WARNING -> language_service.628a85fb2680.root.log.WARNING.20241205-055318.1087\n",
            "drwx------ 2 root root  4096 Dec  5 05:48 pyright-1093-WbEAuO6fPgsx\n",
            "drwx------ 2 root root  4096 Dec  5 05:54 pyright-2839-D24QrdDxnNUn\n",
            "drwx------ 2 root root  4096 Dec  5 05:54 pyright-2839-hEGDxQInb2CK\n",
            "drwxr-xr-x 3 root root  4096 Dec  5 05:54 python-languageserver-cancellation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ygkWw73dRNda"
      },
      "outputs": [],
      "source": [
        "# Clone the repository from GitHub\n",
        "!git clone --depth 1 -q https://github.com/stefan-spiss/MagicWand-TFLite-ESP32-MPU6050.git\n",
        "# Copy the training scripts into our workspace\n",
        "!cp -r MagicWand-TFLite-ESP32-MPU6050/train train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################ Info: let's see what's added..\n",
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9UKumixZ8mv",
        "outputId": "4ae35594-bb5a-4924-e5bc-b232054954ab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 84\n",
            "srwxr-xr-x 1 root root     0 Dec  5 05:44 colab_runtime.sock\n",
            "-rw-r--r-- 1 root root  1299 Dec  5 05:44 dap_multiplexer.628a85fb2680.root.log.INFO.20241205-054419.114\n",
            "lrwxrwxrwx 1 root root    62 Dec  5 05:44 dap_multiplexer.INFO -> dap_multiplexer.628a85fb2680.root.log.INFO.20241205-054419.114\n",
            "srwxr-xr-x 1 root root     0 Dec  5 05:44 debugger_2az7cn5c5v\n",
            "drwx------ 2 root root  4096 Dec  5 05:48 initgoogle_syslog_dir.0\n",
            "-rw-r--r-- 1 root root  7238 Dec  5 05:53 language_service.628a85fb2680.root.log.ERROR.20241205-055318.1087\n",
            "-rw-r--r-- 1 root root 12819 Dec  5 05:54 language_service.628a85fb2680.root.log.INFO.20241205-054805.1087\n",
            "-rw-r--r-- 1 root root  3124 Dec  5 05:59 language_service.628a85fb2680.root.log.INFO.20241205-055445.2833\n",
            "-rw-r--r-- 1 root root  7238 Dec  5 05:53 language_service.628a85fb2680.root.log.WARNING.20241205-055318.1087\n",
            "lrwxrwxrwx 1 root root    65 Dec  5 05:53 language_service.ERROR -> language_service.628a85fb2680.root.log.ERROR.20241205-055318.1087\n",
            "lrwxrwxrwx 1 root root    64 Dec  5 05:54 language_service.INFO -> language_service.628a85fb2680.root.log.INFO.20241205-055445.2833\n",
            "lrwxrwxrwx 1 root root    67 Dec  5 05:53 language_service.WARNING -> language_service.628a85fb2680.root.log.WARNING.20241205-055318.1087\n",
            "drwxr-xr-x 7 root root  4096 Dec  5 06:00 MagicWand-TFLite-ESP32-MPU6050\n",
            "drwx------ 2 root root  4096 Dec  5 05:48 pyright-1093-WbEAuO6fPgsx\n",
            "drwx------ 2 root root  4096 Dec  5 05:54 pyright-2839-D24QrdDxnNUn\n",
            "drwx------ 2 root root  4096 Dec  5 05:54 pyright-2839-hEGDxQInb2CK\n",
            "drwxr-xr-x 3 root root  4096 Dec  5 05:54 python-languageserver-cancellation\n",
            "drwxr-xr-x 2 root root  4096 Dec  5 06:00 train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################ Info: take a look at what's in there.\n",
        "!ls ./MagicWand-TFLite-ESP32-MPU6050/train -l\n",
        "!ls ./train -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77kFaZN_aKDi",
        "outputId": "17588a38-7052-4e33-ea3f-77bf74900700"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 92\n",
            "-rw-r--r-- 1 root root  2889 Dec  5 06:00 data_augmentation.py\n",
            "-rw-r--r-- 1 root root  2096 Dec  5 06:00 data_augmentation_test.py\n",
            "-rw-r--r-- 1 root root  4173 Dec  5 06:00 data_load.py\n",
            "-rw-r--r-- 1 root root  4213 Dec  5 06:00 data_load_test.py\n",
            "-rw-r--r-- 1 root root  3490 Dec  5 06:00 data_plot.py\n",
            "-rw-r--r-- 1 root root  5995 Dec  5 06:00 data_prepare.py\n",
            "-rw-r--r-- 1 root root  2813 Dec  5 06:00 data_prepare_test.py\n",
            "-rw-r--r-- 1 root root  2878 Dec  5 06:00 data_split_person.py\n",
            "-rw-r--r-- 1 root root  1905 Dec  5 06:00 data_split_person_test.py\n",
            "-rw-r--r-- 1 root root  3071 Dec  5 06:00 data_split.py\n",
            "-rw-r--r-- 1 root root  3141 Dec  5 06:00 data_split_test.py\n",
            "-rw-r--r-- 1 root root  3624 Dec  5 06:00 README.md\n",
            "-rw-r--r-- 1 root root    32 Dec  5 06:00 requirements.txt\n",
            "-rw-r--r-- 1 root root 11296 Dec  5 06:00 train_magic_wand_model.ipynb\n",
            "-rw-r--r-- 1 root root  8654 Dec  5 06:00 train.py\n",
            "-rw-r--r-- 1 root root  2849 Dec  5 06:00 train_test.py\n",
            "total 96\n",
            "drwxr-xr-x 6 root root  4096 Oct 28  2023 data\n",
            "-rw-r--r-- 1 root root  2889 Dec  5 06:00 data_augmentation.py\n",
            "-rw-r--r-- 1 root root  2096 Dec  5 06:00 data_augmentation_test.py\n",
            "-rw-r--r-- 1 root root  4173 Dec  5 06:00 data_load.py\n",
            "-rw-r--r-- 1 root root  4213 Dec  5 06:00 data_load_test.py\n",
            "-rw-r--r-- 1 root root  3490 Dec  5 06:00 data_plot.py\n",
            "-rw-r--r-- 1 root root  5995 Dec  5 06:00 data_prepare.py\n",
            "-rw-r--r-- 1 root root  2813 Dec  5 06:00 data_prepare_test.py\n",
            "-rw-r--r-- 1 root root  2878 Dec  5 06:00 data_split_person.py\n",
            "-rw-r--r-- 1 root root  1905 Dec  5 06:00 data_split_person_test.py\n",
            "-rw-r--r-- 1 root root  3071 Dec  5 06:00 data_split.py\n",
            "-rw-r--r-- 1 root root  3141 Dec  5 06:00 data_split_test.py\n",
            "-rw-r--r-- 1 root root  3624 Dec  5 06:00 README.md\n",
            "-rw-r--r-- 1 root root    32 Dec  5 06:00 requirements.txt\n",
            "-rw-r--r-- 1 root root 11296 Dec  5 06:00 train_magic_wand_model.ipynb\n",
            "-rw-r--r-- 1 root root  8654 Dec  5 06:00 train.py\n",
            "-rw-r--r-- 1 root root  2849 Dec  5 06:00 train_test.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXI7R4RehFdU"
      },
      "source": [
        "## Prepare the data\n",
        "\n",
        "Next, we'll extract the data into the expected location within the training scripts' directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "W2Sg2AKzVr2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a11e76-4cf5-40dd-da0a-58ebf191286d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  MagicWand-TFLite-ESP32-MPU6050/data/data.zip\n",
            "   creating: train/data/\n",
            "   creating: train/data/negative/\n",
            "  inflating: train/data/negative/output_negative_Elekas.txt  \n",
            "  inflating: train/data/negative/output_negative_arthur.txt  \n",
            "  inflating: train/data/negative/output_negative_filip.txt  \n",
            "  inflating: train/data/negative/output_negative_kai.txt  \n",
            "  inflating: train/data/negative/output_negative_lukas.txt  \n",
            "  inflating: train/data/negative/output_negative_nico.txt  \n",
            "  inflating: train/data/negative/output_negative_peter.txt  \n",
            "  inflating: train/data/negative/output_negative_stefan.txt  \n",
            "  inflating: train/data/negative/output_negative_yeongmi.txt  \n",
            "   creating: train/data/ring/\n",
            "  inflating: train/data/ring/output_ring_Elekas.txt  \n",
            "  inflating: train/data/ring/output_ring_alex.txt  \n",
            "  inflating: train/data/ring/output_ring_arthur.txt  \n",
            "  inflating: train/data/ring/output_ring_filip.txt  \n",
            "  inflating: train/data/ring/output_ring_justin.txt  \n",
            "  inflating: train/data/ring/output_ring_kai.txt  \n",
            "  inflating: train/data/ring/output_ring_lukas.txt  \n",
            "  inflating: train/data/ring/output_ring_nico.txt  \n",
            "  inflating: train/data/ring/output_ring_patrick.txt  \n",
            "  inflating: train/data/ring/output_ring_peter.txt  \n",
            "  inflating: train/data/ring/output_ring_stefan.txt  \n",
            "  inflating: train/data/ring/output_ring_yeongmi.txt  \n",
            "   creating: train/data/slope/\n",
            "  inflating: train/data/slope/output_slope_arthur.txt  \n",
            "  inflating: train/data/slope/output_slope_best.txt  \n",
            "  inflating: train/data/slope/output_slope_filip.txt  \n",
            "  inflating: train/data/slope/output_slope_justin.txt  \n",
            "  inflating: train/data/slope/output_slope_kai.txt  \n",
            "  inflating: train/data/slope/output_slope_lukas.txt  \n",
            "  inflating: train/data/slope/output_slope_nico.txt  \n",
            "  inflating: train/data/slope/output_slope_patrick.txt  \n",
            "  inflating: train/data/slope/output_slope_peter.txt  \n",
            "  inflating: train/data/slope/output_slope_ruben.txt  \n",
            "  inflating: train/data/slope/output_slope_stefan.txt  \n",
            "  inflating: train/data/slope/output_slope_yeongmi.txt  \n",
            "   creating: train/data/wing/\n",
            "  inflating: train/data/wing/output_wing_Sonja_Jasmin.txt  \n",
            "  inflating: train/data/wing/output_wing_arthur.txt  \n",
            "  inflating: train/data/wing/output_wing_fabian.txt  \n",
            "  inflating: train/data/wing/output_wing_filip.txt  \n",
            "  inflating: train/data/wing/output_wing_kai.txt  \n",
            "  inflating: train/data/wing/output_wing_leo.txt  \n",
            "  inflating: train/data/wing/output_wing_lukas.txt  \n",
            "  inflating: train/data/wing/output_wing_nico.txt  \n",
            "  inflating: train/data/wing/output_wing_patrick.txt  \n",
            "  inflating: train/data/wing/output_wing_peter.txt  \n",
            "  inflating: train/data/wing/output_wing_stefan.txt  \n",
            "  inflating: train/data/wing/output_wing_yeongmi.txt  \n"
          ]
        }
      ],
      "source": [
        "# Extract the data into the train directory\n",
        "!unzip  MagicWand-TFLite-ESP32-MPU6050/data/data.zip -d train\n",
        "#!tar xvzf data.tar.gz -C train 1>/dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################ Info: let's see if the data is there..\n",
        "!ls ./train/data -R"
      ],
      "metadata": {
        "id": "qmfmwZavcerB",
        "outputId": "bb31ecaa-f0b2-46dd-e5d5-5f8d81166e40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./train/data:\n",
            "negative  ring\tslope  wing\n",
            "\n",
            "./train/data/negative:\n",
            "output_negative_arthur.txt  output_negative_kai.txt    output_negative_peter.txt\n",
            "output_negative_Elekas.txt  output_negative_lukas.txt  output_negative_stefan.txt\n",
            "output_negative_filip.txt   output_negative_nico.txt   output_negative_yeongmi.txt\n",
            "\n",
            "./train/data/ring:\n",
            "output_ring_alex.txt\toutput_ring_filip.txt\toutput_ring_lukas.txt\t output_ring_peter.txt\n",
            "output_ring_arthur.txt\toutput_ring_justin.txt\toutput_ring_nico.txt\t output_ring_stefan.txt\n",
            "output_ring_Elekas.txt\toutput_ring_kai.txt\toutput_ring_patrick.txt  output_ring_yeongmi.txt\n",
            "\n",
            "./train/data/slope:\n",
            "output_slope_arthur.txt  output_slope_kai.txt\t   output_slope_peter.txt\n",
            "output_slope_best.txt\t output_slope_lukas.txt    output_slope_ruben.txt\n",
            "output_slope_filip.txt\t output_slope_nico.txt\t   output_slope_stefan.txt\n",
            "output_slope_justin.txt  output_slope_patrick.txt  output_slope_yeongmi.txt\n",
            "\n",
            "./train/data/wing:\n",
            "output_wing_arthur.txt\toutput_wing_leo.txt\t output_wing_peter.txt\n",
            "output_wing_fabian.txt\toutput_wing_lukas.txt\t output_wing_Sonja_Jasmin.txt\n",
            "output_wing_filip.txt\toutput_wing_nico.txt\t output_wing_stefan.txt\n",
            "output_wing_kai.txt\toutput_wing_patrick.txt  output_wing_yeongmi.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNjukI1Sgl2C"
      },
      "source": [
        "We now inspect the data by plotting it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The scripts must be run from within the train directory\n",
        "%cd train\n",
        "# Plot the data\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from data_prepare import prepare_original_data\n",
        "from data_prepare import generate_negative_data\n",
        "\n",
        "LABEL_NAME = \"gesture\"\n",
        "DATA_NAME = \"accel_ms2_xyz\"\n",
        "folders = [\"wing\", \"ring\", \"slope\"]\n",
        "names = [\n",
        "    \"stefan\",\n",
        "    \"patrick\",\n",
        "    \"justin\",\n",
        "    \"yeongmi\"\n",
        "    \"arthur\",\n",
        "    \"kai\",\n",
        "    \"nico\",\n",
        "    \"filip\",\n",
        "    \"lukas\",\n",
        "    \"peter\",\n",
        "]\n",
        "\n",
        "data = []  # pylint: disable=redefined-outer-name\n",
        "for idx1, folder in enumerate(folders):\n",
        "  for idx2, name in enumerate(names):\n",
        "    prepare_original_data(folder, name, data,\n",
        "                          \"./data/%s/output_%s_%s.txt\" % (folder, folder, name))\n",
        "n_gestures = len(data)\n",
        "for idx, name in enumerate(names):\n",
        "  prepare_original_data(\"negative\", name, data,\n",
        "                        \"./data/negative/output_negative_%s.txt\" % (name))\n",
        "n_negative = len(data) - n_gestures\n",
        "folders.append(\"negative\")\n",
        "\n",
        "# if there are more than 10% more gesture samples per gesture as negative samples, generate additional negative\n",
        "# samples\n",
        "if n_gestures - n_negative * len(folders) > n_gestures/len(folders) * 0.1:\n",
        "  print(\"not enough negative samples available, creating random data samples\")\n",
        "  generate_negative_data(data, (math.ceil(n_gestures/len(folders)) - n_negative))\n",
        "n_negative = len(data) - n_gestures\n",
        "\n",
        "columns = [LABEL_NAME, \"name\", DATA_NAME]\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "df_gesture_data = pd.DataFrame()\n",
        "for folder in folders:\n",
        "  for row in df.loc[df[LABEL_NAME] == folder].iterrows():\n",
        "    tmp_data = np.array(row[1][DATA_NAME])\n",
        "    df_tmp = pd.DataFrame({\n",
        "      \"name\": np.full(len(tmp_data), row[1][\"name\"]),\n",
        "      LABEL_NAME: np.full(len(tmp_data), folder),\n",
        "      \"t\": range(len(tmp_data)),\n",
        "      \"X\": tmp_data[:, 0],\n",
        "      \"Y\": tmp_data[:, 1],\n",
        "      \"Z\": tmp_data[:, 2]\n",
        "      })\n",
        "    df_gesture_data = pd.concat([df_gesture_data, df_tmp], ignore_index=True)\n",
        "\n",
        "# print(df_gesture_data)\n",
        "# sb.scatterplot(data = df_gesture_data, x = \"t\", y = \"X\", col)\n",
        "# for folder in folders:\n",
        "#   grid_X = sb.FacetGrid(df_gesture_data.loc[df_gesture_data[LABEL_NAME] == folder], col = \"name\", hue = LABEL_NAME, col_wrap=3)\n",
        "#   grid_X.map(sb.scatterplot, \"t\", \"X\")\n",
        "#   grid_X.add_legend()\n",
        "#   grid_Y = sb.FacetGrid(df_gesture_data.loc[df_gesture_data[LABEL_NAME] == folder], col = \"name\", hue = LABEL_NAME, col_wrap=3)\n",
        "#   grid_Y.map(sb.scatterplot, \"t\", \"Y\")\n",
        "#   grid_Y.add_legend()\n",
        "#   grid_Z = sb.FacetGrid(df_gesture_data.loc[df_gesture_data[LABEL_NAME] == folder], col = \"name\", hue = LABEL_NAME, col_wrap=3)\n",
        "#   grid_Z.map(sb.scatterplot, \"t\", \"Z\")\n",
        "#   grid_Z.add_legend()\n",
        "\n",
        "grid_X = sb.FacetGrid(df_gesture_data, col = LABEL_NAME, hue = \"name\", col_wrap=len(names))\n",
        "grid_X.map(sb.scatterplot, \"t\", \"X\")\n",
        "grid_X.add_legend()\n",
        "grid_Y = sb.FacetGrid(df_gesture_data, col = LABEL_NAME, hue = \"name\", col_wrap=len(names))\n",
        "grid_Y.map(sb.scatterplot, \"t\", \"Y\")\n",
        "grid_Y.add_legend()\n",
        "grid_Z = sb.FacetGrid(df_gesture_data, col = LABEL_NAME, hue = \"name\", col_wrap=len(names))\n",
        "grid_Z.map(sb.scatterplot, \"t\", \"Z\")\n",
        "grid_Z.add_legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ds-mz2e_QVeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll then run the scripts that split the data into training, validation, and test sets."
      ],
      "metadata": {
        "id": "PPayuEIVQZNe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBqSVpi6Vxss"
      },
      "outputs": [],
      "source": [
        "# Prepare the data\n",
        "!python data_prepare.py\n",
        "# Split the data by person\n",
        "#!python data_split_person.py\n",
        "# Split the data randomly since only one person available\n",
        "!python data_split.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-cmVbFvhTvy"
      },
      "source": [
        "## Load TensorBoard\n",
        "\n",
        "Now, we set up TensorBoard so that we can graph our accuracy and loss as training proceeds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCx6SN9NWRPw"
      },
      "outputs": [],
      "source": [
        "# Load TensorBoard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/scalars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERC2Cr4PhaOl"
      },
      "source": [
        "## Begin training\n",
        "\n",
        "The following cell will begin the training process. Training will take around 5 minutes on a GPU runtime. You'll see the metrics in TensorBoard after a few epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXmQZgbuWQFO"
      },
      "outputs": [],
      "source": [
        "#!python train.py --model CNN --person true\n",
        "!python train.py --model CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gXbVzcXhvGD"
      },
      "source": [
        "## Create a C source file\n",
        "\n",
        "The `train.py` script writes a model, `model.tflite`, to the training scripts' directory.\n",
        "\n",
        "In the following cell, we convert this model into a C++ source file we can use with TensorFlow Lite for Microcontrollers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wgei4OGe3Nz"
      },
      "outputs": [],
      "source": [
        "# Install xxd if it is not available\n",
        "!apt-get -qq install xxd\n",
        "# Save the file as a C source file\n",
        "!xxd -i model.tflite > /content/model.cc\n",
        "# Print the source file\n",
        "!cat /content/model.cc"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Train a gesture recognition model for microcontroller (ESP32) use",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}